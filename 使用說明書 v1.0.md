# YOLOv7-tiny Baseline 使用說明書 v1.0

**版本**: v1.0  
**日期**: 2025-08-14  
**適用**: YOLOv7-tiny Baseline 專案  
**PRD 版本**: v1.4

---

## 📋 目錄

1. [專案概述](#專案概述)
2. [系統需求](#系統需求)
3. [安裝指南](#安裝指南)
4. [資料準備](#資料準備)
5. [基礎訓練](#基礎訓練)
6. [實驗系統](#實驗系統)
7. [監控與分析](#監控與分析)
8. [模型導出與量化](#模型導出與量化)
9. [故障排除](#故障排除)
10. [附錄](#附錄)

---

## 🎯 專案概述

### 專案目標
本專案實作 YOLOv7-tiny 模型的完整訓練與量化 Pipeline，專注於在 COCO2017 資料集上進行 320×320 輸入尺寸的訓練。專案嚴格遵循 PRD v1.4 規範，確保結果的可重現性與標準化。

### 核心特色
- **從頭訓練**: 使用隨機權重初始化，不依賴預訓練模型
- **AMP 訓練**: 支援 FP16 混合精度訓練，提升效率
- **多 GPU 支援**: 針對 RTX 4090/5090、H100、B200 優化
- **完整實驗系統**: 效能測試、實驗管理、結果比較
- **PTQ 量化**: ONNX Runtime 靜態量化支援
- **PRD 合規**: 嚴格遵循 PRD v1.4 所有規範

### 預期結果
- **FP16 精度**: mAP@0.5:0.95 約 32-34
- **INT8 量化**: 相比 FP16 掉點 1.5-3.0 mAP
- **跨平台一致性**: 各引擎差異 ≤ 0.5 mAP

### GPU 效能基準 (v2.0 擬真測試)
| GPU | 最佳 FPS | 極限 Batch Size | 相對效能 |
|-----|----------|------------------|----------|
| RTX 4090 | ~2,200 | 768-1024 | 1.0× |
| RTX 5090 | ~2,900 | 1024-1280 | 1.3× |
| H100 | ~5,500 | 1536-2048 | 2.5× |
| B200 | ~9,000 | 2560-4096 | 4.0× |

---

## 🖥️ 系統需求

### 硬體需求

#### 最低需求
- **GPU**: NVIDIA GTX 1660 或以上 (6GB VRAM)
- **CPU**: 4 核心或以上
- **記憶體**: 16GB RAM
- **儲存**: 100GB 可用空間

#### 建議需求
- **GPU**: RTX 4090 (24GB) 或以上
- **CPU**: 8 核心或以上
- **記憶體**: 32GB RAM
- **儲存**: 200GB SSD

#### 支援的高階 GPU
| GPU 型號 | 記憶體 | 建議 Batch Size | 預估訓練時間 |
|----------|--------|-----------------|--------------|
| RTX 4090 | 24GB | 128-256 | ~48 小時 |
| RTX 5090 | 32GB | 256-320 | ~36 小時 |
| H100 | 80GB | 512-640 | ~24 小時 |
| B200 | 192GB | 1024-1280 | ~18 小時 |

### 軟體需求
- **作業系統**: Ubuntu 18.04+ / CentOS 7+ / Windows 10+
- **Python**: 3.8-3.11
- **CUDA**: 11.8+ (支援您的 GPU)
- **Docker**: 可選，用於容器化部署

---

## 🚀 安裝指南

### 步驟 1: 環境準備

#### 1.1 克隆專案
```bash
# 方式 1: 如果您有專案 Git 倉庫
git clone [your-repository-url]
cd yolov7tiny_baseline

# 方式 2: 如果使用現有 YOLOv7 倉庫
git clone https://github.com/WongKinYiu/yolov7.git yolov7tiny_baseline
cd yolov7tiny_baseline
```

#### 1.2 建立虛擬環境
```bash
# 使用 conda (推薦)
conda create -n yolov7tiny python=3.9
conda activate yolov7tiny

# 或使用 venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows
```

### 步驟 2: 安裝相依套件

#### 2.1 基礎套件
```bash
# 安裝 PyTorch (根據您的 CUDA 版本調整)
（runpod 不需要，不要裝！！！)

# 安裝其他相依套件
pip install -r requirements.txt
```

#### 2.2 實驗系統額外套件
```bash
# 監控工具
pip install GPUtil psutil

# 資料分析與視覺化
pip install matplotlib seaborn pandas openpyxl

# ONNX 相關 (用於模型導出)
pip install onnx onnxsim onnxruntime
```

#### 2.3 驗證安裝
```bash
python -c "import torch; print('PyTorch:', torch.__version__); print('CUDA available:', torch.cuda.is_available())"
```

### 步驟 3: 設定 CLAUDE.md
將提供的 CLAUDE.md 檔案放置於專案根目錄，確保 AI 助手能正確理解專案需求。

---

## 📂 資料準備

### 資料集結構

專案使用標準的平行目錄結構：

```
/workspace/                  # 工作區根目錄
├── yolov7tiny_baseline/     # 專案目錄
│   ├── data/coco.yaml       # COCO 配置檔案
│   ├── train.py             # 訓練腳本
│   └── ...
└── coco/                    # COCO 資料集 (與專案平行)
    ├── images/
    │   ├── train2017/       # 訓練圖片
    │   └── val2017/         # 驗證圖片
    └── labels/
        ├── train2017/       # 訓練標籤
        └── val2017/         # 驗證標籤
```

### COCO 資料集準備

#### 方式 1: 自動下載 (推薦)
```bash
# 使用官方腳本下載
bash scripts/get_coco.sh
```

#### 方式 2: 手動下載
1. 下載 COCO2017 資料集：
   - [訓練圖片](http://images.cocodataset.org/zips/train2017.zip)
   - [驗證圖片](http://images.cocodataset.org/zips/val2017.zip)
   - [標籤](http://images.cocodataset.org/annotations/annotations_trainval2017.zip)

2. 解壓並整理目錄結構

#### 方式 3: 預處理 320x320 版本
如果您有預處理的 320x320 版本：
```bash
# 確保路徑正確指向預處理版本
# 修改 data/coco.yaml 中的路徑設定
```

### 設定驗證

執行以下指令確認資料集設定正確：
```bash
python -c "
from utils.datasets import create_dataloader
from utils.general import check_dataset
check_dataset('data/coco.yaml')
print('資料集驗證完成！')
"
```

---

## 🎯 基礎訓練

### 快速開始

#### 基本訓練指令
```bash
# 使用 PRD v1.4 規定的標準參數
python train.py \
  --img 320 \
  --batch 128 \
  --epochs 300 \
  --data data/coco.yaml \
  --weights '' \
  --hyp data/hyp.scratch.tiny.yaml \
  --device 0 \
  --workers 4 \
  --amp \
  --save-period 25
```

#### 多 GPU 訓練
```bash
# 使用 DataParallel (單機多卡)
python train.py \
  --img 320 \
  --batch 256 \
  --epochs 300 \
  --data data/coco.yaml \
  --weights '' \
  --hyp data/hyp.scratch.tiny.yaml \
  --device 0,1,2,3 \
  --workers 8 \
  --amp \
  --save-period 25

# 使用 DistributedDataParallel (建議)
python -m torch.distributed.launch --nproc_per_node=4 train.py \
  --img 320 \
  --batch 64 \
  --epochs 300 \
  --data data/coco.yaml \
  --weights '' \
  --hyp data/hyp.scratch.tiny.yaml \
  --device 0,1,2,3 \
  --workers 8 \
  --amp \
  --save-period 25 \
  --sync-bn
```

### 重要參數說明

| 參數 | 說明 | PRD 規範 | 可調整 |
|------|------|----------|--------|
| `--img` | 輸入圖片尺寸 | 320 | ❌ 固定 |
| `--batch` | 批次大小 | 依 GPU 調整 | ✅ 可調 |
| `--epochs` | 訓練輪數 | 300 | ❌ 固定 |
| `--data` | 資料集配置 | data/coco.yaml | ❌ 固定 |
| `--weights` | 初始權重 | '' (隨機) | ❌ 固定 |
| `--hyp` | 超參數檔案 | hyp.scratch.tiny.yaml | ❌ 固定 |
| `--amp` | 混合精度 | 開啟 | ❌ 固定 |
| `--workers` | 資料載入程序 | 依系統調整 | ✅ 可調 |
| `--device` | 使用的 GPU | 0 或 0,1,2,3 | ✅ 可調 |

### 訓練監控

#### TensorBoard
訓練自動啟用 TensorBoard 記錄：
```bash
# 在另一個終端執行
tensorboard --logdir runs/train
# 瀏覽器開啟: http://localhost:6006
```

#### 即時日誌
訓練過程中會顯示：
```
Epoch    GPU_mem   box_loss   obj_loss   cls_loss   Instances       Size
   0/299      4.42G     0.0576     0.0614     0.0294        89        320: 100%|██| 929/929
               Class     Images  Instances          P          R      mAP50   mAP50-95
                 all       5000      36335      0.693      0.538      0.605      0.377
```

### 訓練結果

完成的訓練會在 `runs/train/exp/` 產生：
- `weights/best.pt` - 最佳模型權重
- `weights/last.pt` - 最終模型權重
- `results.txt` - 訓練結果統計
- `train_batch*.jpg` - 訓練樣本可視化
- `val_batch*.jpg` - 驗證樣本可視化

---

## 🧪 實驗系統

### 實驗系統概述

實驗系統提供完整的多 GPU 效能測試、實驗管理和結果比較功能。包含兩個版本的 GPU 測試工具：
- **v1.0 基礎版**: 快速簡單測試（10 秒完成）
- **v2.0 擬真版**: 完整壓力測試（15-20 分鐘）

### GPU 效能測試 v2.0（擬真版）

#### 新版特色
- **真實資料載入**: 整合 COCO dataloader
- **完整 Loss 計算**: box_loss + obj_loss + cls_loss  
- **OOM 邊界探測**: 自動尋找最大可用 batch size
- **GPU 監控**: 溫度、使用率、記憶體即時追蹤
- **多級別測試**: 輕量(20次)、中等(100次)、重度(200次)

#### 環境準備
```bash
# 安裝必要套件
pip install gputil tqdm

# 驗證環境（無需 GPU）
python tools/gpu_benchmark_quick_test.py
```

#### 完整擬真測試
```bash
# 自動偵測 GPU 並執行完整測試
python tools/gpu_benchmark.py

# 指定 GPU 類型
python tools/gpu_benchmark.py --gpu-type H100

# 快速測試模式（僅 light 級別，2-3 分鐘）
python tools/gpu_benchmark.py --quick

# 自定義測試級別
python tools/gpu_benchmark.py --test-levels light medium

# 跳過 OOM 探測
python tools/gpu_benchmark.py --no-find-limit
```

#### 跨 GPU 效能比較
```bash
# 先執行各 GPU 測試
python tools/gpu_benchmark.py --gpu-type RTX4090
python tools/gpu_benchmark.py --gpu-type H100
python tools/gpu_benchmark.py --gpu-type B200

# 生成比較報告
python tools/gpu_benchmark.py --compare RTX4090 H100 B200
```

#### 測試時間預估
| GPU | 測試模式 | 預估時間 | 總迭代數 |
|-----|----------|----------|----------|
| RTX 4090 | 快速 | 2-3 分鐘 | ~1,000 次 |
| RTX 4090 | 完整 | 15-20 分鐘 | ~4,800 次 |
| H100 | 快速 | 1-2 分鐘 | ~1,500 次 |
| H100 | 完整 | 8-12 分鐘 | ~7,200 次 |
| B200 | 完整 | 6-10 分鐘 | ~9,600 次 |

#### 擬真測試結果範例
```
🏆 RTX4090 擬真效能測試報告
================================================================================
🖥️  GPU: GeForce RTX 4090 (24GB)
💻 系統: 48 核心, 188.0GB RAM
🐍 環境: PyTorch 2.0.1+cu118, CUDA 11.8
🎯 最大 Batch Size: 768

Batch    Level    Status   Time/Batch   Memory     FPS      GPU%   Temp
--------------------------------------------------------------------------------
256      light    ✅       0.123s       9.1GB      2088     95%    67°C
256      medium   ✅       0.125s       9.1GB      2048     96%    69°C
256      heavy    ✅       0.127s       9.1GB      2015     97%    71°C
384      light    ✅       0.178s       13.2GB     2157     96%    68°C
384      medium   ✅       0.181s       13.2GB     2121     97%    70°C
512      light    ✅       0.234s       17.5GB     2188     97%    69°C
768      light    ✅       0.342s       23.8GB     2245     98%    72°C
768      medium   ❌       Out of Mem

🏆 最佳效能配置:
   Batch Size: 768 (light 級別)
   最高 FPS: 2245
   記憶體使用: 23.8GB
   GPU 使用率: 98%
```

### GPU 效能測試 v1.0（基礎版）

保留原始快速測試功能：
```bash
# 使用舊版測試（10 秒完成）
python tools/gpu_benchmark_v1.py
```

### 實驗管理

#### 建立實驗
```bash
# 基本實驗
python tools/experiment_manager.py create --name baseline_test --gpu H100

# 自定義 batch size
python tools/experiment_manager.py create --name large_batch --gpu H100 --batch 512

# 調整學習率 (倍數調整)
python tools/experiment_manager.py create --name high_lr --gpu H100 --lr-mult 1.5

# 調整預熱週期
python tools/experiment_manager.py create --name long_warmup --gpu H100 --warmup 10

# 組合調整
python tools/experiment_manager.py create \
  --name optimized_run \
  --gpu H100 \
  --batch 512 \
  --lr-mult 1.2 \
  --warmup 5
```

#### 管理實驗
```bash
# 列出所有實驗
python tools/experiment_manager.py list

# 執行特定實驗
python tools/experiment_manager.py run baseline_test_H100_20250814_120000
```

#### 實驗目錄結構
```
experiments/
├── experiments_log.json                    # 實驗總日誌
└── baseline_test_H100_20250814_120000/     # 特定實驗
    ├── experiment_config.yaml              # 實驗配置
    ├── hyp_custom.yaml                     # 自定義超參數 (如有)
    ├── run_experiment.sh                   # 執行腳本
    ├── monitoring/                         # 監控資料
    │   ├── metrics_*.csv                   # 詳細指標
    │   └── summary_*.json                  # 監控摘要
    └── [訓練結果檔案]                       # 權重、日誌等
```

### 實驗配置範例

#### GPU 配置檔案 (configs/gpu_configs.yaml)
```yaml
gpu_configs:
  H100:
    name: "NVIDIA H100"
    memory_gb: 80
    optimal_batch_sizes: [256, 384, 512, 640]
    recommended_workers: 16
    mixed_precision: true
    compile_mode: true

base_training:
  img_size: 320
  epochs: 300
  data: "data/coco.yaml"
  weights: ""
  hyp: "data/hyp.scratch.tiny.yaml"
  amp: true
  save_period: 25
```

#### 實驗配置檔案範例
```yaml
experiment_info:
  gpu_type: H100
  created_at: 2025-08-14T12:00:00
  prd_compliance: true
  base_spec: PRD v1.4

training_args:
  img_size: 320
  epochs: 300
  data: data/coco.yaml
  weights: ""
  hyp: experiments/baseline_test_H100_20250814_120000/hyp_custom.yaml
  batch: 512
  workers: 16
  device: 0
  amp: true
  save_period: 25
```

---

## 📊 監控與分析

### 即時監控

#### 啟動監控
```bash
# 監控特定實驗
python tools/monitor_training.py --exp-name baseline_test_H100_20250814_120000

# 自定義監控間隔 (秒)
python tools/monitor_training.py --exp-name your_exp --interval 10
```

#### 監控介面
```
[  45.3min] GPU: 95.2% VRAM: 78.5% (15234MB) Temp: 67.2°C CPU: 34.5% RAM: 18.7GB
```

### 監控指標

#### GPU 指標
- **GPU 使用率**: 計算核心使用率百分比
- **GPU 記憶體**: 已使用 / 總記憶體
- **GPU 溫度**: 運行溫度 (°C)

#### 系統指標
- **CPU 使用率**: 處理器使用率
- **RAM 使用量**: 系統記憶體使用
- **磁碟 I/O**: 讀寫速率

#### 監控檔案
- `metrics_*.csv`: 詳細的時序監控資料
- `summary_*.json`: 監控摘要統計

### 結果比較

#### 基本比較
```bash
# 列印比較摘要
python tools/compare_results.py

# 匯出 Excel 報告
python tools/compare_results.py --export-excel

# 生成比較圖表
python tools/compare_results.py --plot

# 組合使用
python tools/compare_results.py --export-excel --plot --output detailed_analysis
```

#### 比較報告內容
- **實驗摘要表**: 所有實驗的關鍵指標
- **效能對比圖**: mAP、訓練時間、資源使用
- **統計分析**: 平均值、標準差、最佳結果
- **Excel 報告**: 詳細的數據表格

#### 比較指標
- **準確度指標**: mAP@0.5, mAP@0.5:0.95
- **效能指標**: 訓練時間、FPS
- **資源指標**: GPU 使用率、記憶體使用
- **系統指標**: CPU 使用率、功耗

### TensorBoard 分析

#### 啟動 TensorBoard
```bash
# 單一實驗
tensorboard --logdir runs/train/exp

# 多實驗比較
tensorboard --logdir runs/train

# 指定連接埠
tensorboard --logdir runs/train --port 6007
```

#### TensorBoard 指標
- **Loss 曲線**: box_loss, obj_loss, cls_loss
- **準確度曲線**: mAP@0.5, mAP@0.5:0.95
- **學習率曲線**: lr0, lr1, lr2
- **樣本可視化**: 訓練和驗證樣本

---

## 📦 模型導出與量化

### ONNX 導出

#### 基本導出
```bash
# 導出為 ONNX 格式
python export.py \
  --weights runs/train/exp/weights/best.pt \
  --img 320 320 \
  --batch 1 \
  --include onnx \
  --opset 13

# 簡化模型
python -m onnxsim best.onnx best_simplified.onnx
```

#### 高階導出選項
```bash
# 動態 batch size
python export.py \
  --weights best.pt \
  --img 320 320 \
  --batch 1 \
  --include onnx \
  --dynamic \
  --opset 13

# 包含 NMS
python export.py \
  --weights best.pt \
  --img 320 320 \
  --batch 1 \
  --include onnx \
  --end2end \
  --opset 13
```

### PTQ 量化

#### 準備校正集
```bash
# 生成校正集清單 (512 張圖片)
python tools/generate_calib_list.py \
  --dataset-path ../coco/images/val2017 \
  --output calib.txt \
  --count 512
```

#### 執行 PTQ 量化
```bash
# ONNX Runtime 靜態量化
python tools/ort_ptq.py \
  --model best_simplified.onnx \
  --calib-list calib.txt \
  --output best_quantized.onnx \
  --quant-format QDQ
```

#### 量化參數
- **權重量化**: INT8, symmetric, per-channel
- **激活量化**: INT8, asymmetric, per-tensor
- **校正集**: 512 張無增強圖片
- **格式**: QDQ (Quantize-Dequantize)

### 模型評測

#### 基本評測
```bash
# FP16 模型評測
python test.py \
  --data data/coco.yaml \
  --img 320 \
  --batch 32 \
  --weights best.pt \
  --device 0

# ONNX 模型評測
python tools/eval_onnx.py \
  --model best_simplified.onnx \
  --data data/coco.yaml \
  --img 320 \
  --batch 32
```

#### 評測參數 (PRD 規定)
```bash
# 使用標準 NMS 參數
--conf-thres 0.001 \
--iou-thres 0.65 \
--max-det 300
```

#### 評測結果解讀
```
Class     Images  Instances        P        R    mAP50 mAP50-95
  all       5000      36335    0.693    0.538    0.605    0.377

Results saved to runs/test/exp/
```

### 跨平台部署

#### 支援的推理引擎
- **ONNX Runtime**: CPU/GPU 推理
- **TensorRT**: NVIDIA GPU 優化
- **OpenVINO**: Intel 硬體優化
- **CoreML**: Apple 裝置部署

#### 轉換範例
```bash
# TensorRT 轉換
trtexec --onnx=best_quantized.onnx \
        --saveEngine=best.trt \
        --fp16 \
        --workspace=1024

# OpenVINO 轉換
mo --input_model best_quantized.onnx \
   --output_dir openvino_model
```

---

## 🔧 故障排除

### 常見問題

#### 1. 記憶體不足 (OOM)
**現象**: `RuntimeError: CUDA out of memory`

**解決方案**:
```bash
# 1. 降低 batch size
python tools/gpu_benchmark.py  # 測試合適的 batch size

# 2. 減少 workers
--workers 4  # 或更少

# 3. 使用梯度累積
--accumulate 2  # 累積 2 個 batch 再更新

# 4. 清理 GPU 記憶體
python -c "import torch; torch.cuda.empty_cache()"
```

#### 2. 資料載入錯誤
**現象**: `FileNotFoundError` 或 `Image not found`

**解決方案**:
```bash
# 1. 檢查資料集路徑
python -c "
from utils.general import check_dataset
check_dataset('data/coco.yaml')
"

# 2. 驗證 coco.yaml 設定
cat data/coco.yaml

# 3. 檢查資料夾結構
ls ../coco/images/train2017/ | head -5
ls ../coco/labels/train2017/ | head -5
```

#### 3. 訓練速度慢
**可能原因與解決方案**:

```bash
# 1. 檢查 GPU 使用率
nvidia-smi

# 2. 調整 workers 數量
--workers 8  # 根據 CPU 核心數調整

# 3. 使用 SSD 儲存資料
# 將資料集移動到 SSD

# 4. 檢查網路頻寬 (如果使用網路儲存)
# 使用本地儲存
```

#### 4. 實驗系統錯誤
**現象**: 實驗建立或執行失敗

**解決方案**:
```bash
# 1. 檢查相依套件
pip install GPUtil psutil matplotlib seaborn pandas openpyxl

# 2. 檢查 GPU 偵測
python -c "import GPUtil; print(GPUtil.getGPUs())"

# 3. 檢查目錄權限
chmod +x experiments/*/run_experiment.sh

# 4. 檢查磁碟空間
df -h
```

#### 5. TensorBoard 無法開啟
**解決方案**:
```bash
# 1. 檢查是否安裝
pip install tensorboard

# 2. 指定不同連接埠
tensorboard --logdir runs/train --port 6007

# 3. 檢查防火牆設定
# 開放 6006 連接埠

# 4. 使用公開地址 (雲端環境)
tensorboard --logdir runs/train --host 0.0.0.0
```

### 效能優化

#### GPU 效能優化
```bash
# 1. 確保使用最新驅動
nvidia-smi

# 2. 設定 GPU 功耗模式
nvidia-smi -pm 1  # 持續模式
nvidia-smi -pl 400  # 設定功率限制 (W)

# 3. 檢查 GPU 溫度
nvidia-smi -q -d temperature

# 4. 使用混合精度
--amp  # 已在基本指令中包含
```

#### 系統效能優化
```bash
# 1. 調整系統參數
echo 'net.core.rmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 134217728' >> /etc/sysctl.conf

# 2. 設定 CPU 親和性
taskset -c 0-7 python train.py ...

# 3. 使用高效能模式
echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
```

### 除錯工具

#### 訓練除錯
```bash
# 1. 單步除錯
python train.py --debug --epochs 1

# 2. 資料載入測試
python -c "
from utils.datasets import create_dataloader
dataloader = create_dataloader('data/coco.yaml', 320, 32, 0, hyp=None)[0]
for i, (imgs, targets, paths, _) in enumerate(dataloader):
    print(f'Batch {i}: {imgs.shape}, {len(targets)} targets')
    if i >= 2: break
"

# 3. 模型前向測試
python -c "
import torch
from models.yolo import Model
model = Model('cfg/training/yolov7-tiny.yaml')
x = torch.randn(1, 3, 320, 320)
y = model(x)
print('Model output shapes:', [yi.shape for yi in y])
"
```

#### 實驗除錯
```bash
# 1. 檢查實驗配置
python tools/experiment_manager.py create --name debug_test --gpu RTX4090 --batch 64
cat experiments/debug_test_*/experiment_config.yaml

# 2. 手動執行實驗
cd experiments/debug_test_*
bash run_experiment.sh

# 3. 檢查監控日誌
python tools/monitor_training.py --exp-name debug_test --interval 1
```

---

## 📖 附錄

### A. PRD v1.4 規範對照表

| 項目 | PRD 要求 | 實作狀態 | 備註 |
|------|----------|----------|------|
| 模型 | YOLOv7-tiny | ✅ 實作 | cfg/training/yolov7-tiny.yaml |
| 輸入尺寸 | 320×320 | ✅ 實作 | --img 320 |
| 訓練 epoch | 300 | ✅ 實作 | --epochs 300 |
| 初始權重 | 隨機 | ✅ 實作 | --weights '' |
| 超參數檔案 | hyp.scratch.tiny.yaml | ✅ 實作 | 不可修改 |
| AMP | 啟用 | ✅ 實作 | --amp |
| 資料集 | COCO2017 | ✅ 實作 | 官方 split |
| NMS 參數 | 固定 | ✅ 實作 | conf=0.001, iou=0.65 |
| PTQ 格式 | QDQ | ✅ 實作 | ONNX Runtime |
| 校正集 | 512 張 | ✅ 實作 | 無增強 |

### B. 檔案結構參考

```
yolov7tiny_baseline/
├── CLAUDE.md                    # AI 助手指令
├── PRD v1.4.md                  # 產品需求文件
├── 使用說明書 v1.0.md            # 本文件
├── README_EXPERIMENT.md          # 實驗系統快速指南
├── requirements.txt              # Python 相依套件
├── data/
│   ├── coco.yaml                # COCO 資料集配置
│   └── hyp.scratch.tiny.yaml    # 超參數檔案 (不可修改)
├── cfg/
│   └── training/
│       └── yolov7-tiny.yaml     # 模型配置
├── configs/
│   └── gpu_configs.yaml         # GPU 配置檔案
├── tools/
│   ├── gpu_benchmark.py         # GPU 擬真效能測試 v2.0
│   ├── gpu_benchmark_v1.py      # GPU 基礎測試 v1.0
│   ├── gpu_benchmark_quick_test.py  # 環境驗證工具
│   ├── experiment_manager.py    # 實驗管理系統
│   ├── monitor_training.py      # 訓練監控工具
│   ├── compare_results.py       # 結果比較工具
│   └── ort_ptq.py              # PTQ 量化工具
├── experiments/                 # 實驗結果目錄
├── runs/                        # 訓練輸出目錄
├── train.py                     # 訓練腳本
├── export.py                    # 模型導出腳本
├── test.py                      # 模型評測腳本
└── utils/                       # 工具函數
```

### C. 指令快速參考

#### 基礎操作
```bash
# 基本訓練
python train.py --img 320 --batch 128 --epochs 300 --data data/coco.yaml --weights '' --hyp data/hyp.scratch.tiny.yaml --device 0 --workers 4 --amp --save-period 25

# 模型評測
python test.py --data data/coco.yaml --img 320 --batch 32 --weights runs/train/exp/weights/best.pt

# ONNX 導出
python export.py --weights runs/train/exp/weights/best.pt --img 320 320 --batch 1 --include onnx --opset 13
```

#### GPU 擬真效能測試 v2.0
```bash
# 環境驗證
python tools/gpu_benchmark_quick_test.py

# 完整擬真測試
python tools/gpu_benchmark.py

# 快速測試（2-3 分鐘）
python tools/gpu_benchmark.py --quick

# 指定 GPU 和測試級別
python tools/gpu_benchmark.py --gpu-type H100 --test-levels light medium

# 跨 GPU 效能比較
python tools/gpu_benchmark.py --compare RTX4090 H100 B200

# 舊版快速測試（10 秒）
python tools/gpu_benchmark_v1.py
```

#### 實驗管理
```bash
# 建立實驗
python tools/experiment_manager.py create --name test --gpu H100

# 列出實驗
python tools/experiment_manager.py list

# 執行實驗
python tools/experiment_manager.py run [實驗ID]

# 監控訓練
python tools/monitor_training.py --exp-name [實驗ID]

# 比較結果
python tools/compare_results.py --export-excel --plot
```

#### TensorBoard
```bash
# 啟動 TensorBoard
tensorboard --logdir runs/train

# 指定連接埠
tensorboard --logdir runs/train --port 6007
```

### D. 常用環境變數

```bash
# CUDA 相關
export CUDA_VISIBLE_DEVICES=0,1,2,3
export CUDA_LAUNCH_BLOCKING=1  # 除錯用

# PyTorch 相關
export TORCH_HOME=/path/to/torch/cache
export PYTHONPATH=/path/to/yolov7tiny_baseline

# 效能優化
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8
```

### E. 技術支援

#### 問題回報
如遇到問題，請提供以下資訊：
1. 錯誤訊息完整內容
2. 使用的指令
3. GPU 型號和驅動版本
4. Python 和 PyTorch 版本
5. 系統環境 (OS, CUDA 版本)

#### 效能基準
不同 GPU 的參考效能 (300 epochs)：

| GPU | Batch Size | 訓練時間 | mAP@0.5:0.95 | 備註 |
|-----|------------|----------|--------------|------|
| RTX 4090 | 256 | ~48h | 32.8 | 最佳性價比 |
| RTX 5090 | 320 | ~36h | 33.1 | 新一代架構 |
| H100 | 512 | ~24h | 33.3 | 企業級效能 |
| B200 | 1024 | ~18h | 33.5 | 頂級效能 |

*以上數據為參考值，實際結果可能因系統配置而異*

---

**文件版本**: v1.0  
**最後更新**: 2025-08-14  
**維護**: YOLOv7-tiny Baseline 專案團隊

© 2025 YOLOv7-tiny Baseline Project. 保留所有權利。